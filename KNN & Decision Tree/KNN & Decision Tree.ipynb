{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data', header=None, na_values=['?'])\n",
    "data.columns= ['ID', 'Clump Thickness', 'Uniformity of Cell Size','Uniformity of Cell Shape', \\\n",
    "                    'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', \\\n",
    "                    'Mitoses', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Clump Thickness  Uniformity of Cell Size  \\\n",
       "0  1000025                5                        1   \n",
       "1  1002945                5                        4   \n",
       "2  1015425                3                        1   \n",
       "3  1016277                6                        8   \n",
       "4  1017023                4                        1   \n",
       "\n",
       "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
       "0                         1                  1                            2   \n",
       "1                         4                  5                            7   \n",
       "2                         1                  1                            2   \n",
       "3                         8                  1                            3   \n",
       "4                         1                  3                            2   \n",
       "\n",
       "   Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
       "0          1.0                3                1        1      2  \n",
       "1         10.0                3                2        1      2  \n",
       "2          2.0                3                1        1      2  \n",
       "3          4.0                3                7        1      2  \n",
       "4          1.0                3                1        1      2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                              0\n",
       "Clump Thickness                 0\n",
       "Uniformity of Cell Size         0\n",
       "Uniformity of Cell Shape        0\n",
       "Marginal Adhesion               0\n",
       "Single Epithelial Cell Size     0\n",
       "Bare Nuclei                    16\n",
       "Bland Chromatin                 0\n",
       "Normal Nucleoli                 0\n",
       "Mitoses                         0\n",
       "Class                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check missing values, we find there are 16 missing vlaues in 'Bare Nuclei'\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## impute missing value, since 'Bare Nuclei' is ordinal data, we use the mode value to fill missing vlaues\n",
    "data['Bare Nuclei'].fillna(data['Bare Nuclei'].mode()[0], inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               int64\n",
      "Clump Thickness                  int64\n",
      "Uniformity of Cell Size          int64\n",
      "Uniformity of Cell Shape         int64\n",
      "Marginal Adhesion                int64\n",
      "Single Epithelial Cell Size      int64\n",
      "Bare Nuclei                    float64\n",
      "Bland Chromatin                  int64\n",
      "Normal Nucleoli                  int64\n",
      "Mitoses                          int64\n",
      "Class                            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check the type of data\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "3                6                        8                         8   \n",
       "4                4                        1                         1   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "0                  1                            2          1.0   \n",
       "1                  5                            7         10.0   \n",
       "2                  1                            2          2.0   \n",
       "3                  1                            3          4.0   \n",
       "4                  3                            2          1.0   \n",
       "\n",
       "   Bland Chromatin  Normal Nucleoli  Mitoses  \n",
       "0                3                1        1  \n",
       "1                3                2        1  \n",
       "2                3                1        1  \n",
       "3                3                7        1  \n",
       "4                3                1        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.iloc[:, 1:10]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 4,\n",
       "       2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4,\n",
       "       4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4,\n",
       "       2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4,\n",
       "       2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 2,\n",
       "       4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2,\n",
       "       2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4,\n",
       "       2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2,\n",
       "       2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2,\n",
       "       2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4,\n",
       "       4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4,\n",
       "       4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2,\n",
       "       4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4,\n",
       "       4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2,\n",
       "       2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2,\n",
       "       2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2,\n",
       "       4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2,\n",
       "       2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4,\n",
       "       2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2,\n",
       "       2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4,\n",
       "       2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2,\n",
       "       4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the data for KNN, standardize the data \n",
    "df_x = np.array(df)\n",
    "df_x= (df_x - df_x.mean()) / df_x.std()\n",
    "df_y = np.array(data['Class'])\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  1.,  1., ...,  3.,  1.,  1.],\n",
       "       [ 5.,  4.,  4., ...,  3.,  2.,  1.],\n",
       "       [ 3.,  1.,  1., ...,  3.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 5., 10., 10., ...,  8., 10.,  2.],\n",
       "       [ 4.,  8.,  6., ..., 10.,  6.,  1.],\n",
       "       [ 4.,  8.,  8., ..., 10.,  4.,  1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get the data for Decision Tree algorithm\n",
    "x = np.array(df)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## distance function\n",
    "def dist(p1, p2):\n",
    "    return np.sum(np.square(p1-p2))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, training_data, training_labels):\n",
    "        self.X_train = training_data\n",
    "        self.y_train = training_labels\n",
    "        \n",
    "    def neighbors(self, obs):\n",
    "        distances = []\n",
    "        ### get the neighbors of point\n",
    "        for i, p in enumerate(self.X_train):\n",
    "            distances.append((i, dist(obs, p)))\n",
    "        distances_sort = sorted(distances, key = lambda x:x[1])\n",
    "        index = [d[0] for d in distances_sort[:self.k]]\n",
    "        return self.y_train[index]\n",
    "    \n",
    "    '''\n",
    "    def labels(self, neighbors):\n",
    "        ### find the most voted label\n",
    "        label, count = None, 0\n",
    "        for l in set(neighs):\n",
    "            if neighs.count(l) > count:\n",
    "                count = neighs.count(l)\n",
    "                label = l\n",
    "        return label\n",
    "            \n",
    "    '''    \n",
    "\n",
    "    def predict(self, test_data):\n",
    "        predictions = []\n",
    "        for obs in test_data:\n",
    "            neighs = self.neighbors(obs)\n",
    "        \n",
    "            ## find the most voted label \n",
    "            label, count = None, 0\n",
    "            for l in set(neighs):\n",
    "                if list(neighs).count(l) > count:\n",
    "                    count = list(neighs).count(l)\n",
    "                    label = l\n",
    "            predictions.append(label)\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def accuracy_score(self, predicted_labels, labels):\n",
    "        TP = sum((predicted_labels==4) & (labels==4))\n",
    "        TN = sum((predicted_labels==2) & (labels==2))\n",
    "        return (TP + TN) / len(labels)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## confusion matrix function; 2 for benign, 4 for malignant; malignant is True\n",
    "## the accuracy, TPR, PPV, TNR, F1_score\n",
    "def confusion_matrix(predicted_labels, labels):\n",
    "    FP = sum((labels==2) & (predicted_labels==4))\n",
    "    FN = sum((labels==4) & (predicted_labels==2))\n",
    "    TP = sum((labels==4) & (predicted_labels==4))\n",
    "    TN = sum((labels==2) & (predicted_labels==2))\n",
    "    \n",
    "    ## print performance metrics\n",
    "    accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "    TPR = TP / (TP + FN)\n",
    "    PPV = TP / (TP + FP)\n",
    "    TNR = TN / (TN + FP)\n",
    "    F1_score = 2*PPV*TPR / (PPV+TPR)\n",
    "    metric = pd.DataFrame([accuracy, TPR, PPV, TNR, F1_score], ['ACCU', 'TPR', 'PPV', 'TNR', 'F1'], ['score'])\n",
    "    \n",
    "    ### print confusion matrix\n",
    "    conf_matrix = np.array([[TP, FN], [FP, TN]])\n",
    "    conf = pd.DataFrame(conf_matrix, ['malignant', 'benign'], ['malignant', 'benign'])\n",
    "    return metric, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dicision tree implementaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attr, thre):\n",
    "        self.attr = attr\n",
    "        self.thre = thre\n",
    "        self.height = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.leaf = False\n",
    "        self.predict = None\n",
    "\n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self, criterion='entropy', max_depth=None, impurity_thre=None):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.colnames = None\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.impurity_thre = impurity_thre\n",
    "    \n",
    "    ## calculate the impurity measure we use, like gini, entropy, missclassification rate\n",
    "    def impurity_measure(self, training_data, training_labels):\n",
    "        impurity = None\n",
    "        ## positve label and negative label\n",
    "        p, n = sum(training_labels==4), sum(training_labels==2)\n",
    "        if self.criterion == 'entropy':   ## entropy\n",
    "            if p==0 or n==0:\n",
    "                impurity = 0\n",
    "            else:\n",
    "                impurity = -1*(p/(p+n)*math.log(p/(p+n),2) + n/(p+n)*math.log(n/(p+n),2))\n",
    "            return impurity  \n",
    "        if self.criterion == 'gini':      ## gini index, the smaller the better\n",
    "            if p==0 or n==0:\n",
    "                impurity = 0\n",
    "            else:\n",
    "                impurity = 1 - (p/(p+n))**2 - (n/(p+n))**2\n",
    "            return impurity  \n",
    "        if self.criterion == 'misclassification error':\n",
    "            if p==0 or n==0:\n",
    "                return 0\n",
    "            else:\n",
    "                impurity = 1- max(p/(p+n), n/(p+n))\n",
    "            return impurity\n",
    "        else:\n",
    "            print('Error, please specify a impurity measure !')\n",
    "    \n",
    "    def impurity_decrease(self, training_data, training_labels, attr, threshold):\n",
    "        sub_x1, sub_y1 = training_data[training_data[:, attr] > threshold], training_labels[training_data[:, attr] > threshold]\n",
    "        sub_x2, sub_y2 = training_data[training_data[:, attr] < threshold], training_labels[training_data[:, attr] < threshold]\n",
    "        length = len(training_labels)\n",
    "        \n",
    "        impurity = self.impurity_measure(training_data, training_labels)\n",
    "        \n",
    "        # calcualte weighted impurity after split\n",
    "        impurity_split = len(sub_y1) / length * self.impurity_measure(sub_x1, sub_y1) + len(sub_y2) / length * self.impurity_measure(sub_x2, sub_y2)\n",
    "        \n",
    "        # return impurity decrease\n",
    "        return impurity - impurity_split\n",
    "\n",
    "    ## choose the best split value for each attribute\n",
    "    def chose_thre(self, training_data, training_labels, attr):\n",
    "        # since it is ordinal data, we can find the threshold by iterating (v1+v2)/2\n",
    "        values = set(training_data[:, attr])    # unique values\n",
    "        values_sort = sorted(list(values))\n",
    "        attr_thre = 0\n",
    "        max_im_dec = float('-inf')\n",
    "        \n",
    "        # try all thresholds values \n",
    "        for i in range(len(values_sort)-1):\n",
    "            thre = (values_sort[i] + values_sort[i+1])/2\n",
    "            im_dec = self.impurity_decrease(training_data, training_labels, attr, thre)\n",
    "            if im_dec > max_im_dec:\n",
    "                max_im_dec = im_dec\n",
    "                attr_thre = thre\n",
    "        # find the best attr threshold\n",
    "        return attr_thre\n",
    "    \n",
    "    # select the best attr based on the informaiton gain and threshold\n",
    "    def chose_attr(self, training_data, training_labels):\n",
    "        max_im_dec = float('-inf')\n",
    "        best_thre = None\n",
    "        best_attr = None\n",
    "        for attr in range(training_data.shape[1]):\n",
    "            thre = self.chose_thre(training_data, training_labels, attr)\n",
    "            im_dec  = self.impurity_decrease(training_data, training_labels, attr, thre)\n",
    "            # chose the best attribute and the threshold associated\n",
    "            if im_dec > max_im_dec:\n",
    "                max_im_dec = im_dec\n",
    "                best_attr = attr\n",
    "                best_thre = thre\n",
    "        \n",
    "        return best_attr, best_thre\n",
    "    \n",
    "    # build the decision tree\n",
    "    def build_tree(self, training_data, training_labels, depth=1):\n",
    "        P, N = sum(training_labels==4), sum(training_labels==2)\n",
    "        \n",
    "        # P==0 or N==0\n",
    "        if P==0 or N==0:\n",
    "            leaf = Node(None, None)\n",
    "            leaf.leaf = True\n",
    "            leaf.predict = 4 if P > N else 2\n",
    "            return leaf\n",
    "        # max_depth\n",
    "        elif depth >= self.max_depth:\n",
    "            # create a leaf none, since it is well separated\n",
    "            leaf = Node(None, None)\n",
    "            leaf.leaf = True\n",
    "            leaf.predict = 4 if P > N else 2\n",
    "            return leaf\n",
    "        else:\n",
    "            best_attr, best_thre = self.chose_attr(training_data, training_labels)\n",
    "            impurity = self.impurity_decrease(training_data, training_labels, best_attr, best_thre)\n",
    "            # impurity threshold\n",
    "            if impurity < self.impurity_thre:\n",
    "                # create a leaf none, since it is well separated\n",
    "                leaf = Node(None, None)\n",
    "                leaf.leaf = True\n",
    "                leaf.predict = 4 if P > N else 2\n",
    "                return leaf\n",
    "                 \n",
    "            else:\n",
    "                root = Node(best_attr, best_thre)\n",
    "\n",
    "                # split data \n",
    "                sub_x1 = training_data[training_data[:, best_attr] < best_thre]\n",
    "                sub_y1 = training_labels[training_data[:, best_attr] < best_thre]\n",
    "                sub_x2 = training_data[training_data[:, best_attr] > best_thre]\n",
    "                sub_y2 = training_labels[training_data[:, best_attr] > best_thre] \n",
    "\n",
    "                # recursively bulid the tree\n",
    "                root.left = self.build_tree(sub_x1, sub_y1, depth+1)\n",
    "                root.right = self.build_tree(sub_x2, sub_y2, depth+1)\n",
    "\n",
    "                return root\n",
    "    \n",
    "    def print_tree(self, root, level=0):\n",
    "        print(level*' ', end=' ')\n",
    "        if root.leaf:\n",
    "            print(root.predict)\n",
    "        else:\n",
    "            print('%s < %.3f' %(self.colnames[root.attr], root.thre))\n",
    "        \n",
    "        if root.left:\n",
    "            self.print_tree(root.left, level+1)\n",
    "        if root.right:\n",
    "            self.print_tree(root.right, level + 1)\n",
    "        \n",
    "    # the depth of a tree   \n",
    "    def height(self, root):\n",
    "        height_left = 0\n",
    "        height_right = 0\n",
    "        if root.left:\n",
    "            height_left = self.height(root.left)\n",
    "        if root.right:\n",
    "            height_right = self.height(root.right)\n",
    "        if height_left > height_right:\n",
    "            return height_left + 1\n",
    "        else:\n",
    "            return height_right + 1\n",
    "            \n",
    "            \n",
    "    # fit the training data\n",
    "    def fit(self, training_data, training_labels, colnames):\n",
    "        self.X_train = training_data\n",
    "        self.y_train = training_labels\n",
    "        self.colnames = colnames\n",
    "        \n",
    "    # predict testing data\n",
    "    def predict(self, root, test_data):\n",
    "        \n",
    "        ## define a function to get the prediction for each obs\n",
    "        def predict_obs(node, obs):\n",
    "            if node.leaf:\n",
    "                return node.predict\n",
    "            if obs[node.attr] < node.thre:\n",
    "                return predict_obs(node.left, obs)\n",
    "            else:\n",
    "                return predict_obs(node.right, obs)\n",
    "        \n",
    "        predictions = []\n",
    "        for obs in test_data:\n",
    "            pred = predict_obs(root, obs)\n",
    "            predictions.append(pred)\n",
    "        return np.array(predictions)\n",
    "        \n",
    "    def accuracy_score(self, predicted_labels, labels):\n",
    "        TP = sum((predicted_labels==4) & (labels==4))\n",
    "        TN = sum((predicted_labels==2) & (labels==2))\n",
    "        return (TP + TN) / len(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validataion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64938942 0.75549346 0.82181715 0.86459853 0.90512955 0.94148238\n",
      " 0.96564001 0.98927807 1.        ]\n"
     ]
    }
   ],
   "source": [
    "## run pca analysis, get the principle components, the first 5 components\n",
    "x_mean = x - x.mean()\n",
    "u, s, vh = np.linalg.svd(x_mean)\n",
    "\n",
    "s2 = np.cumsum(s**2) / np.sum(s**2)\n",
    "print(s2)\n",
    "\n",
    "pc_x = x_mean @ vh.T[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## random split data, training dataset (80%) and test dataset (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "knn_train_x, knn_test_x, knn_train_y, knn_test_y = train_test_split(df_x, df_y, test_size=0.2)\n",
    "dt_train_x, dt_test_x, dt_train_y, dt_test_y = train_test_split(x, df_y, test_size=0.2)\n",
    "dt_pca_train_x, dt_pca_test_x, dt_pca_train_y, dt_pca_test_y = train_test_split(pc_x, df_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "## run k-folder cross validation function \n",
    "def cv_train_test_split(X, Y, kfolder= 10):\n",
    "    X_split, Y_split = [], []\n",
    "    index = list(range(len(Y)))\n",
    "    random.shuffle(index)   ## shuffle the index to random select\n",
    "    fold_size = int(len(X) / kfolder) + (len(X)%kfolder > 0)\n",
    "    for i in range(kfolder):\n",
    "        X_fold = X[index[i*fold_size: (i+1)*fold_size]]\n",
    "        Y_fold = Y[index[i*fold_size: (i+1)*fold_size]]\n",
    "        X_split.append(X_fold)\n",
    "        Y_split.append(Y_fold)\n",
    "    return X_split, Y_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_X, knn_Y = cv_train_test_split(knn_train_x, knn_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for k= 2 is 0.937\n",
      "The accuracy score for k= 3 is 0.966\n",
      "The accuracy score for k= 4 is 0.962\n",
      "The accuracy score for k= 5 is 0.964\n",
      "The accuracy score for k= 6 is 0.962\n",
      "The accuracy score for k= 7 is 0.961\n",
      "The accuracy score for k= 8 is 0.957\n",
      "The accuracy score for k= 17 is 0.961\n",
      "The accuracy score for k= 33 is 0.961\n"
     ]
    }
   ],
   "source": [
    "### KNN, to get the best k \n",
    "for k in [2,3,4,5,6,7,8,17,33]:\n",
    "    scores = []\n",
    "    for i in range(10):\n",
    "        x_train, x_test = np.concatenate(knn_X[:i] + knn_X[i+1:], axis = 0), knn_X[i]\n",
    "        y_train, y_test = np.concatenate(knn_Y[:i] + knn_Y[i+1:], axis = 0), knn_Y[i]\n",
    "        clf = KNN(k)\n",
    "        clf.fit(x_train, y_train)\n",
    "        p = clf.predict(x_test)\n",
    "        scores.append(clf.accuracy_score(p, y_test))\n",
    "    print('The accuracy score for k= %s is %.3f' %(str(k), sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## k=3 is the best, run KNN with test data with k=33\n",
    "k=3\n",
    "clf = KNN(k)\n",
    "clf.fit(knn_train_x, knn_train_y)\n",
    "p = clf.predict(knn_test_x)\n",
    "metric, confusion = confusion_matrix(p, knn_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACCU</th>\n",
       "      <td>0.957143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPR</th>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNR</th>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score\n",
       "ACCU  0.957143\n",
       "TPR   0.926829\n",
       "PPV   0.926829\n",
       "TNR   0.969697\n",
       "F1    0.926829"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>malignant</th>\n",
       "      <th>benign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>malignant</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign</th>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           malignant  benign\n",
       "malignant         38       3\n",
       "benign             3      96"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## decison tree\n",
    "dtree_X, dtree_Y = cv_train_test_split(dt_train_x, dt_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for k=2, im=0.0 is 0.927\n",
      "The accuracy score for k=2, im=0.05 is 0.927\n",
      "The accuracy score for k=2, im=0.1 is 0.927\n",
      "The accuracy score for k=2, im=0.15 is 0.927\n",
      "The accuracy score for k=2, im=0.2 is 0.927\n",
      "The accuracy score for k=2, im=0.25 is 0.927\n",
      "The accuracy score for k=3, im=0.0 is 0.939\n",
      "The accuracy score for k=3, im=0.05 is 0.939\n",
      "The accuracy score for k=3, im=0.1 is 0.936\n",
      "The accuracy score for k=3, im=0.15 is 0.928\n",
      "The accuracy score for k=3, im=0.2 is 0.925\n",
      "The accuracy score for k=3, im=0.25 is 0.927\n",
      "The accuracy score for k=4, im=0.0 is 0.952\n",
      "The accuracy score for k=4, im=0.05 is 0.952\n",
      "The accuracy score for k=4, im=0.1 is 0.950\n",
      "The accuracy score for k=4, im=0.15 is 0.945\n",
      "The accuracy score for k=4, im=0.2 is 0.928\n",
      "The accuracy score for k=4, im=0.25 is 0.927\n",
      "The accuracy score for k=5, im=0.0 is 0.946\n",
      "The accuracy score for k=5, im=0.05 is 0.948\n",
      "The accuracy score for k=5, im=0.1 is 0.946\n",
      "The accuracy score for k=5, im=0.15 is 0.941\n",
      "The accuracy score for k=5, im=0.2 is 0.928\n",
      "The accuracy score for k=5, im=0.25 is 0.927\n",
      "The accuracy score for k=6, im=0.0 is 0.937\n",
      "The accuracy score for k=6, im=0.05 is 0.939\n",
      "The accuracy score for k=6, im=0.1 is 0.937\n",
      "The accuracy score for k=6, im=0.15 is 0.946\n",
      "The accuracy score for k=6, im=0.2 is 0.928\n",
      "The accuracy score for k=6, im=0.25 is 0.927\n",
      "The accuracy score for k=7, im=0.0 is 0.941\n",
      "The accuracy score for k=7, im=0.05 is 0.943\n",
      "The accuracy score for k=7, im=0.1 is 0.945\n",
      "The accuracy score for k=7, im=0.15 is 0.945\n",
      "The accuracy score for k=7, im=0.2 is 0.928\n",
      "The accuracy score for k=7, im=0.25 is 0.927\n",
      "The accuracy score for k=8, im=0.0 is 0.934\n",
      "The accuracy score for k=8, im=0.05 is 0.936\n",
      "The accuracy score for k=8, im=0.1 is 0.943\n",
      "The accuracy score for k=8, im=0.15 is 0.945\n",
      "The accuracy score for k=8, im=0.2 is 0.928\n",
      "The accuracy score for k=8, im=0.25 is 0.927\n",
      "The accuracy score for k=9, im=0.0 is 0.936\n",
      "The accuracy score for k=9, im=0.05 is 0.937\n",
      "The accuracy score for k=9, im=0.1 is 0.945\n",
      "The accuracy score for k=9, im=0.15 is 0.946\n",
      "The accuracy score for k=9, im=0.2 is 0.928\n",
      "The accuracy score for k=9, im=0.25 is 0.927\n",
      "The accuracy score for k=10, im=0.0 is 0.934\n",
      "The accuracy score for k=10, im=0.05 is 0.936\n",
      "The accuracy score for k=10, im=0.1 is 0.945\n",
      "The accuracy score for k=10, im=0.15 is 0.946\n",
      "The accuracy score for k=10, im=0.2 is 0.928\n",
      "The accuracy score for k=10, im=0.25 is 0.927\n"
     ]
    }
   ],
   "source": [
    "### decision tree\n",
    "### parameters: max_depth k from 2 to 10, impurity_decrease from 0 to 0.25 by step 0.05\n",
    "score_matrix = np.zeros((9, 6))\n",
    "\n",
    "for k in range(2,11):\n",
    "    for im in [x/100 for x in range(0, 30, 5)]:\n",
    "        scores = []\n",
    "        for i in range(10):\n",
    "            x_train, x_test = np.concatenate(dtree_X[:i] + dtree_X[i+1:], axis = 0), dtree_X[i]\n",
    "            y_train, y_test = np.concatenate(dtree_Y[:i] + dtree_Y[i+1:], axis = 0), dtree_Y[i]\n",
    "            t = DecisionTree('entropy', k, im)\n",
    "            t.fit(x_train, y_train, colnames)\n",
    "            tree = t.build_tree(x_train, y_train)\n",
    "            p = t.predict(tree, x_test)\n",
    "            scores.append(t.accuracy_score(p, y_test))\n",
    "        score_matrix[k-2, int(im*20)] = sum(scores)/len(scores)\n",
    "        print('The accuracy score for k=%s, im=%s is %.3f' %(str(k), str(im), sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## heatmap\n",
    "def plotHeatMap(data, x_title='X Axis', y_title='Y Axis', title='', x_ticks=[], y_ticks=[]):\n",
    "    \n",
    "    #Plot it out\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.gca()\n",
    "    heatmap = ax.pcolor(data, edgecolors='k', alpha=0.8)\n",
    "    \n",
    "    fig.colorbar(heatmap, ax=ax)\n",
    "    \n",
    "    # turn off the frame\n",
    "    #ax.set_frame_on(False)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(len(x_ticks)) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(len(y_ticks)) + 0.5, minor=False)\n",
    "    \n",
    "    ax.set_xticklabels([str(i/20) for i in x_ticks], minor=False)\n",
    "    ax.set_yticklabels([str(y) for y in y_ticks], minor=False)\n",
    "    \n",
    "    ax.set_xlabel(x_title)\n",
    "    ax.set_ylabel(y_title)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEWCAYAAACHVDePAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3e4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotHeatMap(score_matrix, y_title='max depth', x_title='impurtiy decrease',\\\n",
    "            title='Accuracy Score', y_ticks=range(2,11), x_ticks=range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.926688</td>\n",
       "      <td>0.926688</td>\n",
       "      <td>0.926688</td>\n",
       "      <td>0.926688</td>\n",
       "      <td>0.926688</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.939221</td>\n",
       "      <td>0.939221</td>\n",
       "      <td>0.935649</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.924903</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.951721</td>\n",
       "      <td>0.951721</td>\n",
       "      <td>0.949935</td>\n",
       "      <td>0.944545</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.946364</td>\n",
       "      <td>0.948149</td>\n",
       "      <td>0.946364</td>\n",
       "      <td>0.940974</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.937435</td>\n",
       "      <td>0.939221</td>\n",
       "      <td>0.937435</td>\n",
       "      <td>0.946331</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.940974</td>\n",
       "      <td>0.942760</td>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.944545</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.933831</td>\n",
       "      <td>0.935617</td>\n",
       "      <td>0.942792</td>\n",
       "      <td>0.944545</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.935649</td>\n",
       "      <td>0.937435</td>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.946331</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.933864</td>\n",
       "      <td>0.935649</td>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.946331</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.926688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0.0      0.25       0.5      0.75       1.0      1.25\n",
       "2   0.926688  0.926688  0.926688  0.926688  0.926688  0.926688\n",
       "3   0.939221  0.939221  0.935649  0.928474  0.924903  0.926688\n",
       "4   0.951721  0.951721  0.949935  0.944545  0.928474  0.926688\n",
       "5   0.946364  0.948149  0.946364  0.940974  0.928474  0.926688\n",
       "6   0.937435  0.939221  0.937435  0.946331  0.928474  0.926688\n",
       "7   0.940974  0.942760  0.944578  0.944545  0.928474  0.926688\n",
       "8   0.933831  0.935617  0.942792  0.944545  0.928474  0.926688\n",
       "9   0.935649  0.937435  0.944578  0.946331  0.928474  0.926688\n",
       "10  0.933864  0.935649  0.944578  0.946331  0.928474  0.926688"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame(score_matrix, index = range(2,11), columns=[str(x/20) for x in range(0,30,5)])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree height for entropy is 4\n",
      "         score\n",
      "ACCU  0.921429\n",
      "TPR   0.909091\n",
      "PPV   0.851064\n",
      "TNR   0.927083\n",
      "F1    0.879121\n",
      "           malignant  benign\n",
      "malignant         40       4\n",
      "benign             7      89\n"
     ]
    }
   ],
   "source": [
    "## max_depth is 4 and the impurity_increase=0.05 is the best, run DTree with test data\n",
    "k, im = 4, 0.05\n",
    "t = DecisionTree('entropy', k, im)\n",
    "t.fit(dt_train_x, dt_train_y, colnames)\n",
    "tree = t.build_tree(dt_train_x, dt_train_y)\n",
    "print(\"The tree height for entropy is %d\" % t.height(tree))\n",
    "p = t.predict(tree, dt_test_x)\n",
    "# metrics \n",
    "metric, confusion = confusion_matrix(p, dt_test_y)\n",
    "print(metric)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree height for gini is 4\n",
      "         score\n",
      "ACCU  0.914286\n",
      "TPR   0.840909\n",
      "PPV   0.880952\n",
      "TNR   0.947917\n",
      "F1    0.860465\n",
      "           malignant  benign\n",
      "malignant         37       7\n",
      "benign             5      91\n"
     ]
    }
   ],
   "source": [
    "## max_depth is 4 and the impurity_increase=0.05 is the best, run DTree with test data\n",
    "k, im = 4, 0.05\n",
    "t = DecisionTree('gini', k, im)\n",
    "t.fit(dt_train_x, dt_train_y, colnames)\n",
    "tree = t.build_tree(dt_train_x, dt_train_y)\n",
    "print(\"The tree height for gini is %d\" % t.height(tree))\n",
    "p = t.predict(tree, dt_test_x)\n",
    "# metrics \n",
    "metric, confusion = confusion_matrix(p, dt_test_y)\n",
    "print(metric)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree height for misclassification error is 2\n",
      "         score\n",
      "ACCU  0.907143\n",
      "TPR   0.818182\n",
      "PPV   0.878049\n",
      "TNR   0.947917\n",
      "F1    0.847059\n",
      "           malignant  benign\n",
      "malignant         36       8\n",
      "benign             5      91\n"
     ]
    }
   ],
   "source": [
    "## max_depth is 4 and the impurity_increase=0.05 is the best, run DTree with test data\n",
    "k, im = 4, 0.05\n",
    "t = DecisionTree('misclassification error', k, im)\n",
    "t.fit(dt_train_x, dt_train_y, colnames)\n",
    "tree = t.build_tree(dt_train_x, dt_train_y)\n",
    "print(\"The tree height for misclassification error is %d\" % t.height(tree))\n",
    "p = t.predict(tree, dt_test_x)\n",
    "# metrics \n",
    "metric, confusion = confusion_matrix(p, dt_test_y)\n",
    "print(metric)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_X, pca_Y= cv_train_test_split(dt_pca_train_x, dt_pca_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for k=2, im=0.0 is 0.973\n",
      "The accuracy score for k=2, im=0.05 is 0.973\n",
      "The accuracy score for k=2, im=0.1 is 0.973\n",
      "The accuracy score for k=2, im=0.15 is 0.973\n",
      "The accuracy score for k=2, im=0.2 is 0.973\n",
      "The accuracy score for k=2, im=0.25 is 0.973\n",
      "The accuracy score for k=3, im=0.0 is 0.973\n",
      "The accuracy score for k=3, im=0.05 is 0.973\n",
      "The accuracy score for k=3, im=0.1 is 0.973\n",
      "The accuracy score for k=3, im=0.15 is 0.973\n",
      "The accuracy score for k=3, im=0.2 is 0.973\n",
      "The accuracy score for k=3, im=0.25 is 0.973\n",
      "The accuracy score for k=4, im=0.0 is 0.971\n",
      "The accuracy score for k=4, im=0.05 is 0.973\n",
      "The accuracy score for k=4, im=0.1 is 0.973\n",
      "The accuracy score for k=4, im=0.15 is 0.973\n",
      "The accuracy score for k=4, im=0.2 is 0.973\n",
      "The accuracy score for k=4, im=0.25 is 0.973\n",
      "The accuracy score for k=5, im=0.0 is 0.968\n",
      "The accuracy score for k=5, im=0.05 is 0.970\n",
      "The accuracy score for k=5, im=0.1 is 0.973\n",
      "The accuracy score for k=5, im=0.15 is 0.973\n",
      "The accuracy score for k=5, im=0.2 is 0.973\n",
      "The accuracy score for k=5, im=0.25 is 0.973\n",
      "The accuracy score for k=6, im=0.0 is 0.970\n",
      "The accuracy score for k=6, im=0.05 is 0.971\n",
      "The accuracy score for k=6, im=0.1 is 0.973\n",
      "The accuracy score for k=6, im=0.15 is 0.973\n",
      "The accuracy score for k=6, im=0.2 is 0.973\n",
      "The accuracy score for k=6, im=0.25 is 0.973\n",
      "The accuracy score for k=7, im=0.0 is 0.968\n",
      "The accuracy score for k=7, im=0.05 is 0.970\n",
      "The accuracy score for k=7, im=0.1 is 0.973\n",
      "The accuracy score for k=7, im=0.15 is 0.973\n",
      "The accuracy score for k=7, im=0.2 is 0.973\n",
      "The accuracy score for k=7, im=0.25 is 0.973\n",
      "The accuracy score for k=8, im=0.0 is 0.966\n",
      "The accuracy score for k=8, im=0.05 is 0.968\n",
      "The accuracy score for k=8, im=0.1 is 0.973\n",
      "The accuracy score for k=8, im=0.15 is 0.973\n",
      "The accuracy score for k=8, im=0.2 is 0.973\n",
      "The accuracy score for k=8, im=0.25 is 0.973\n",
      "The accuracy score for k=9, im=0.0 is 0.968\n",
      "The accuracy score for k=9, im=0.05 is 0.970\n",
      "The accuracy score for k=9, im=0.1 is 0.973\n",
      "The accuracy score for k=9, im=0.15 is 0.973\n",
      "The accuracy score for k=9, im=0.2 is 0.973\n",
      "The accuracy score for k=9, im=0.25 is 0.973\n",
      "The accuracy score for k=10, im=0.0 is 0.968\n",
      "The accuracy score for k=10, im=0.05 is 0.970\n",
      "The accuracy score for k=10, im=0.1 is 0.973\n",
      "The accuracy score for k=10, im=0.15 is 0.973\n",
      "The accuracy score for k=10, im=0.2 is 0.973\n",
      "The accuracy score for k=10, im=0.25 is 0.973\n"
     ]
    }
   ],
   "source": [
    "### decision tree with pca\n",
    "score_pca_matrix = np.zeros((9, 6))\n",
    "for k in range(2,11):\n",
    "    for im in [x/100 for x in range(0, 30, 5)]:\n",
    "        scores = []\n",
    "        for i in range(10):\n",
    "            x_train, x_test = np.concatenate(pca_X[:i] + pca_X[i+1:], axis = 0), pca_X[i]\n",
    "            y_train, y_test = np.concatenate(pca_Y[:i] + pca_Y[i+1:], axis = 0), pca_Y[i]\n",
    "            t = DecisionTree('entropy', k, im)\n",
    "            t.fit(x_train, y_train, colnames)\n",
    "            tree = t.build_tree(x_train, y_train)\n",
    "            p = t.predict(tree, x_test)\n",
    "            scores.append(t.accuracy_score(p, y_test))\n",
    "        print('The accuracy score for k=%s, im=%s is %.3f' %(str(k), str(im), sum(scores)/len(scores)))\n",
    "        score_pca_matrix[k-2, int(im*20)] = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEWCAYAAACHVDePAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsjczGwSc7M3MBgEnezOzQeD/A0HQtix0SL2iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c25d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotHeatMap(score_pca_matrix, y_title='max depth', x_title='impurtiy decrease',\\\n",
    "            title='Accuracy Score', y_ticks=range(2,11), x_ticks=range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971396</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.967792</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.969578</td>\n",
       "      <td>0.971364</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.967792</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.965974</td>\n",
       "      <td>0.967760</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.967760</td>\n",
       "      <td>0.969545</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.967760</td>\n",
       "      <td>0.969545</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "      <td>0.973182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0.0      0.25       0.5      0.75       1.0      1.25\n",
       "2   0.973182  0.973182  0.973182  0.973182  0.973182  0.973182\n",
       "3   0.973182  0.973182  0.973182  0.973182  0.973182  0.973182\n",
       "4   0.971396  0.973182  0.973182  0.973182  0.973182  0.973182\n",
       "5   0.967792  0.969578  0.973182  0.973182  0.973182  0.973182\n",
       "6   0.969578  0.971364  0.973182  0.973182  0.973182  0.973182\n",
       "7   0.967792  0.969578  0.973182  0.973182  0.973182  0.973182\n",
       "8   0.965974  0.967760  0.973182  0.973182  0.973182  0.973182\n",
       "9   0.967760  0.969545  0.973182  0.973182  0.973182  0.973182\n",
       "10  0.967760  0.969545  0.973182  0.973182  0.973182  0.973182"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_pca_df = pd.DataFrame(score_pca_matrix, index = range(2,11), columns=[str(x/20) for x in range(0,30,5)])\n",
    "score_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree height for entropy is 4\n",
      "         score\n",
      "ACCU  0.964286\n",
      "TPR   1.000000\n",
      "PPV   0.909091\n",
      "TNR   0.944444\n",
      "F1    0.952381\n",
      "           malignant  benign\n",
      "malignant         50       0\n",
      "benign             5      85\n"
     ]
    }
   ],
   "source": [
    "## max_depth is 4 and the impurity_increase=0.05 is the best, run DTree with test data\n",
    "k, im = 4, 0.05\n",
    "t = DecisionTree('entropy', k, im)\n",
    "t.fit(dt_pca_train_x, dt_pca_train_y, colnames)\n",
    "tree = t.build_tree(dt_pca_train_x, dt_pca_train_y)\n",
    "print(\"The tree height for entropy is %d\" % t.height(tree))\n",
    "p = t.predict(tree, dt_pca_test_x)\n",
    "# metrics \n",
    "metric, confusion = confusion_matrix(p, dt_pca_test_y)\n",
    "print(metric)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree height for gini index is 2\n",
      "         score\n",
      "ACCU  0.964286\n",
      "TPR   1.000000\n",
      "PPV   0.909091\n",
      "TNR   0.944444\n",
      "F1    0.952381\n",
      "           malignant  benign\n",
      "malignant         50       0\n",
      "benign             5      85\n"
     ]
    }
   ],
   "source": [
    "## max_depth is 4 and the impurity_increase=0.05 is the best, run DTree with test data\n",
    "k, im = 4, 0.05\n",
    "t = DecisionTree('gini', k, im)\n",
    "t.fit(dt_pca_train_x, dt_pca_train_y, colnames)\n",
    "tree = t.build_tree(dt_pca_train_x, dt_pca_train_y)\n",
    "print(\"The tree height for gini index is %d\" % t.height(tree))\n",
    "p = t.predict(tree, dt_pca_test_x)\n",
    "# metrics \n",
    "metric, confusion = confusion_matrix(p, dt_pca_test_y)\n",
    "print(metric)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree height for misclassification error is 2\n",
      "         score\n",
      "ACCU  0.964286\n",
      "TPR   1.000000\n",
      "PPV   0.909091\n",
      "TNR   0.944444\n",
      "F1    0.952381\n",
      "           malignant  benign\n",
      "malignant         50       0\n",
      "benign             5      85\n"
     ]
    }
   ],
   "source": [
    "## max_depth is 4 and the impurity_increase=0.05 is the best, run DTree with test data\n",
    "k, im = 4, 0.05\n",
    "t = DecisionTree('misclassification error', k, im)\n",
    "t.fit(dt_pca_train_x, dt_pca_train_y, colnames)\n",
    "tree = t.build_tree(dt_pca_train_x, dt_pca_train_y)\n",
    "print(\"The tree height for misclassification error is %d\" % t.height(tree))\n",
    "p = t.predict(tree, dt_pca_test_x)\n",
    "# metrics \n",
    "metric, confusion = confusion_matrix(p, dt_pca_test_y)\n",
    "print(metric)\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
